{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8dd00d-9edb-4709-888d-4d8b6993315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Tweet     Label\n",
      "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
      "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
      "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
      "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
      "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
      "...                                                  ...       ...\n",
      "12755  film tncfu , tidak cocok untuk penonton yang t...  negative\n",
      "12756  indihome ini mahal loh bayar nya . hanya , pen...  negative\n",
      "12757  be de gea , cowok cupu yang takut dengan pacar...  negative\n",
      "12758  valen yang sangat tidak berkualitas . konentat...  negative\n",
      "12759  restoran ini menjadi tempat pilihan saya berbu...  positive\n",
      "\n",
      "[12760 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membaca file Excel\n",
    "df = pd.read_excel('Indonlu_Sentiment.xlsx')\n",
    "\n",
    "# Menampilkan dataset\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9760af0c-4372-437b-9d6c-b4452aea61f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Risma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Tweet  \\\n",
      "0      warung ini dimiliki oleh pengusaha pabrik tahu...   \n",
      "1      mohon ulama lurus dan k212 mmbri hujjah partai...   \n",
      "2      lokasi strategis di jalan sumatera bandung . t...   \n",
      "3      betapa bahagia nya diri ini saat unboxing pake...   \n",
      "4      duh . jadi mahasiswa jangan sombong dong . kas...   \n",
      "...                                                  ...   \n",
      "12755  film tncfu , tidak cocok untuk penonton yang t...   \n",
      "12756  indihome ini mahal loh bayar nya . hanya , pen...   \n",
      "12757  be de gea , cowok cupu yang takut dengan pacar...   \n",
      "12758  valen yang sangat tidak berkualitas . konentat...   \n",
      "12759  restoran ini menjadi tempat pilihan saya berbu...   \n",
      "\n",
      "                                            cleaned_text  \n",
      "0      warung milik usaha pabrik puluh kenal putih ba...  \n",
      "1      mohon ulama lurus k212 mmbri hujjah partai diw...  \n",
      "2      lokasi strategis jalan sumatera bandung nya ny...  \n",
      "3      betapa bahagia nya unboxing paket barang nya b...  \n",
      "4      duh mahasiswa sombong kasih kartu kuning ajar ...  \n",
      "...                                                  ...  \n",
      "12755                film tncfu cocok tonton suka sadis2  \n",
      "12756     indihome mahal loh bayar nya tangan nya lambat  \n",
      "12757  be de gea cowok cupu takut pacar nya pacar nya...  \n",
      "12758  valen kualitas konentator nya didik jebret jeb...  \n",
      "12759  restoran pilih buka puasa minggu layan pilhan ...  \n",
      "\n",
      "[12760 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords bahasa Indonesia dari NLTK\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Inisialisasi stemmer dari Sastrawi\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Fungsi preprocessing teks\n",
    "def preprocess_text(text):\n",
    "    # Ubah teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Hapus tanda baca\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Stemming setiap kata dalam teks\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split())\n",
    "    \n",
    "    # Hapus stopwords (bahasa Indonesia)\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Terapkan preprocessing pada kolom yang sesuai\n",
    "df['cleaned_text'] = df['Tweet'].apply(preprocess_text) \n",
    "\n",
    "# Tampilkan kolom teks asli dan teks yang sudah dibersihkan\n",
    "print(df[['Tweet', 'cleaned_text']]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1fe34ff-2f2e-454b-a49b-96df5348d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['00' '000' '005' ... 'zupazupa' 'zuppa' 'zwitsal']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vektorisasi teks\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Menampilkan hasil vektorisasi\n",
    "print(X.toarray()) #convert hasil kedalam bentuk array\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b8cc1f7-dd60-4257-83be-0efbdedcf0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (9570, 14831), Test Shape: (3190, 14831)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Menampilkan bentuk data latih dan data uji\n",
    "print(f'Train Shape: {X_train.shape}, Test Shape: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f349089f-5fe8-4bee-8e6f-7c5a452c2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Naive Bayes: 0.7752351097178684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.65      0.69      1065\n",
      "     neutral       0.94      0.24      0.38       320\n",
      "    positive       0.78      0.94      0.86      1805\n",
      "\n",
      "    accuracy                           0.78      3190\n",
      "   macro avg       0.82      0.61      0.64      3190\n",
      "weighted avg       0.79      0.78      0.75      3190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "print(\"Akurasi Naive Bayes:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3668fb-474d-455d-b288-a25b58bb197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Decision Tree: 0.754858934169279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.68      0.67      1065\n",
      "     neutral       0.60      0.49      0.54       320\n",
      "    positive       0.83      0.85      0.84      1805\n",
      "\n",
      "    accuracy                           0.75      3190\n",
      "   macro avg       0.70      0.67      0.68      3190\n",
      "weighted avg       0.75      0.75      0.75      3190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Membuat model Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi data uji\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"Akurasi Decision Tree:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e803e6c0-c4b4-4714-b26b-0435dda878ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi sentimen (Naive Bayes): positive\n",
      "Prediksi sentimen (Decision Tree): positive\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text, model, vectorizer):\n",
    "    cleaned_text =preprocess_text(text)\n",
    "    text_vector = vectorizer.transform([cleaned_text])\n",
    "    prediction = model.predict(text_vector)\n",
    "    return prediction[0]\n",
    "\n",
    "new_text = \"Saya sangat puas dengan produk ini!\"\n",
    "print(\"Prediksi sentimen (Naive Bayes):\", predict_sentiment(new_text, nb_model, vectorizer))\n",
    "print(\"Prediksi sentimen (Decision Tree):\",predict_sentiment(new_text, dt_model, vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68fde4f7-4901-41b5-b035-94a372fe3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Naive Bayes: 0.7793103448275862\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Download stopwords bahasa Indonesia dari NLTK jika belum ada\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Mengambil stopwords dalam bentuk set\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "# Fungsi preprocessing teks tanpa stemming\n",
    "def preprocess_text(text):\n",
    "    # Ubah teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Hapus tanda baca\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Hapus stopwords (bahasa Indonesia)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Membaca dataset Indonlu Sentiment dari file .xlsx\n",
    "df = pd.read_excel('Indonlu_Sentiment.xlsx')\n",
    "\n",
    "# Terapkan preprocessing pada kolom yang sesuai\n",
    "df['cleaned_text'] = df['Tweet'].apply(preprocess_text)  # Ganti 'text' dengan nama kolom yang benar\n",
    "\n",
    "# Vektorisasi teks\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Memisahkan label\n",
    "y = df['Label']  # Pastikan 'Label' sesuai dengan nama kolom di DataFrame\n",
    "\n",
    "# Membagi data menjadi data latih dan data uji\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Melatih model Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi data uji\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Menghitung dan menampilkan akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Akurasi Naive Bayes:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
