{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793139f1-5286-4147-9a73-314068312e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dari CSV (IMdb Review):\n",
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n",
      "\n",
      "Dataset dari Excel (Ulasan Produk):\n",
      "                                                   Tweet     Label\n",
      "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
      "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
      "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
      "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
      "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
      "...                                                  ...       ...\n",
      "12755  film tncfu , tidak cocok untuk penonton yang t...  negative\n",
      "12756  indihome ini mahal loh bayar nya . hanya , pen...  negative\n",
      "12757  be de gea , cowok cupu yang takut dengan pacar...  negative\n",
      "12758  valen yang sangat tidak berkualitas . konentat...  negative\n",
      "12759  restoran ini menjadi tempat pilihan saya berbu...  positive\n",
      "\n",
      "[12760 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membaca file CSV\n",
    "df_imdb = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Membaca file Excel\n",
    "df_indo = pd.read_excel('Indonlu_Sentiment.xlsx')\n",
    "\n",
    "# Menampilkan kedua dataset\n",
    "print(\"Dataset dari CSV (IMdb Review):\")\n",
    "print(df_imdb)\n",
    "\n",
    "print(\"\\nDataset dari Excel (Ulasan Produk):\")\n",
    "print(df_indo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92807907-348e-4729-ac60-025dcbbc13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Risma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset IMDB setelah pembersihan:\n",
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  one reviewers mentioned watching oz episode yo...  \n",
      "1  wonderful little production br br filming tech...  \n",
      "2  thought wonderful way spend time hot summer we...  \n",
      "3  basically theres family little boy jake thinks...  \n",
      "4  petter matteis love time money visually stunni...  \n",
      "\n",
      "Dataset Bahasa Indonesia setelah pembersihan:\n",
      "                                               Tweet  \\\n",
      "0  warung ini dimiliki oleh pengusaha pabrik tahu...   \n",
      "1  mohon ulama lurus dan k212 mmbri hujjah partai...   \n",
      "2  lokasi strategis di jalan sumatera bandung . t...   \n",
      "3  betapa bahagia nya diri ini saat unboxing pake...   \n",
      "4  duh . jadi mahasiswa jangan sombong dong . kas...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  warung dimiliki pengusaha pabrik puluhan terke...  \n",
      "1  mohon ulama lurus mmbri hujjah partai diwlh su...  \n",
      "2  lokasi strategis jalan sumatera bandung nya ny...  \n",
      "3  betapa bahagia nya unboxing paket barang nya b...  \n",
      "4  duh mahasiswa sombong kasih kartu kuning belaj...  \n"
     ]
    }
   ],
   "source": [
    "# Import untuk preprocessing\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Fungsi membersihkan teks\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Konversi teks menjadi lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Menghapus teks dalam tanda []\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Menghapus angka\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Menghapus tanda baca\n",
    "    text = re.sub(r'\\n', '', text)  # Menghapus newline\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Menghapus spasi ganda\n",
    "    return text\n",
    "\n",
    "# Fungsi menghapus stopwords\n",
    "def remove_stopwords(text, language='english'):\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "# Load dataset\n",
    "df_imdb = pd.read_csv('IMDB Dataset.csv')\n",
    "df_indo = pd.read_excel('Indonlu_Sentiment.xlsx')\n",
    "\n",
    "# Preprocessing dataset IMDB\n",
    "df_imdb['cleaned_text'] = df_imdb['review'].apply(clean_text)\n",
    "df_imdb['cleaned_text'] = df_imdb['cleaned_text'].apply(remove_stopwords, language='english')\n",
    "\n",
    "# Preprocessing dataset bahasa Indonesia\n",
    "df_indo['cleaned_text'] = df_indo['Tweet'].apply(clean_text)\n",
    "df_indo['cleaned_text'] = df_indo['cleaned_text'].apply(remove_stopwords, language='indonesian')\n",
    "\n",
    "# Menampilkan hasil pembersihan\n",
    "print(\"Dataset IMDB setelah pembersihan:\")\n",
    "print(df_imdb[['review', 'cleaned_text']].head())\n",
    "\n",
    "print(\"\\nDataset Bahasa Indonesia setelah pembersihan:\")\n",
    "print(df_indo[['Tweet', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006af4f0-d3a9-49ca-8ed8-27f0e871390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vektorisasi IMDB (beberapa baris):\n",
      "[[0.         0.         0.         ... 0.11423438 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.16255777 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.17315243]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "Terms IMDB:\n",
      "['able' 'absolutely' 'across' 'act' 'acting' 'action' 'actor' 'actors'\n",
      " 'actress' 'actually']\n",
      "\n",
      "Vektorisasi Bahasa Indonesia (beberapa baris):\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Terms Bahasa Indonesia:\n",
      "['acara' 'agama' 'ahok' 'air' 'akses' 'ala' 'alam' 'ambil' 'an' 'anak']\n"
     ]
    }
   ],
   "source": [
    "# Import untuk vektorisasi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vektorisasi dataset IMDB\n",
    "vectorizer_imdb = TfidfVectorizer(max_features=500, max_df=0.95, min_df=5)  # Membuat instance baru untuk dataset IMDB\n",
    "X_imdb = vectorizer_imdb.fit_transform(df_imdb['cleaned_text'])  # Vektorisasi\n",
    "terms_imdb = vectorizer_imdb.get_feature_names_out()  # Mendapatkan nama fitur\n",
    "\n",
    "# Menampilkan beberapa hasil vektorisasi IMDB\n",
    "print(\"Vektorisasi IMDB (beberapa baris):\")\n",
    "print(X_imdb[0:5, :].toarray())  # Menampilkan 5 baris pertama\n",
    "print(\"Terms IMDB:\")\n",
    "print(terms_imdb[:10])  # Menampilkan 10 istilah pertama\n",
    "\n",
    "# Vektorisasi dataset Bahasa Indonesia\n",
    "vectorizer_indo = TfidfVectorizer(max_features=500, max_df=0.95, min_df=5)  # Membuat instance baru untuk dataset Bahasa Indonesia\n",
    "X_indo = vectorizer_indo.fit_transform(df_indo['cleaned_text'])  # Vektorisasi\n",
    "terms_indo = vectorizer_indo.get_feature_names_out()  # Mendapatkan nama fitur\n",
    "\n",
    "# Menampilkan beberapa hasil vektorisasi Bahasa Indonesia\n",
    "print(\"\\nVektorisasi Bahasa Indonesia (beberapa baris):\")\n",
    "print(X_indo[0:5, :].toarray())  # Menampilkan 5 baris pertama\n",
    "print(\"Terms Bahasa Indonesia:\")\n",
    "print(terms_indo[:10])  # Menampilkan 10 istilah pertama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7692ec9f-bde0-49a1-a7e9-7c1750982cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape IMDB: (40000, 500), Test Shape IMDB: (10000, 500)\n",
      "Train Shape Indonesian: (10208, 500), Test Shape Indonesian: (2552, 500)\n"
     ]
    }
   ],
   "source": [
    "# Definisikan y_imdb dan y_indo sebagai label dari masing-masing dataset\n",
    "y_imdb = df_imdb['sentiment']  # Kolom label untuk dataset IMDB\n",
    "y_indo = df_indo['Label']  # Kolom label untuk dataset Bahasa Indonesia\n",
    "\n",
    "# Setelah itu, lakukan pembagian train-test\n",
    "X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = train_test_split(X_imdb, y_imdb, test_size=0.2, random_state=42)\n",
    "X_train_indo, X_test_indo, y_train_indo, y_test_indo = train_test_split(X_indo, y_indo, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menampilkan bentuk data latih dan uji\n",
    "print(f'Train Shape IMDB: {X_train_imdb.shape}, Test Shape IMDB: {X_test_imdb.shape}')\n",
    "print(f'Train Shape Indonesian: {X_train_indo.shape}, Test Shape Indonesian: {X_test_indo.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119796ae-74a6-4697-a5dc-6f31b63891e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Logistic Regression (IMDB): 0.843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84      4961\n",
      "    positive       0.84      0.85      0.85      5039\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "Akurasi Logistic Regression (Indo): 0.7942789968652038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.75      0.73       849\n",
      "     neutral       0.68      0.38      0.49       257\n",
      "    positive       0.86      0.89      0.88      1446\n",
      "\n",
      "    accuracy                           0.79      2552\n",
      "   macro avg       0.75      0.68      0.70      2552\n",
      "weighted avg       0.79      0.79      0.79      2552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Inisialisasi model Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Melatih model dengan data latih IMDB\n",
    "lr_model.fit(X_train_imdb, y_train_imdb)\n",
    "\n",
    "# Memprediksi data uji IMDB\n",
    "y_pred_lr_imdb = lr_model.predict(X_test_imdb)\n",
    "\n",
    "# Menghitung akurasi IMDB\n",
    "print(\"Akurasi Logistic Regression (IMDB):\", accuracy_score(y_test_imdb, y_pred_lr_imdb))\n",
    "print(classification_report(y_test_imdb, y_pred_lr_imdb))\n",
    "\n",
    "# Melatih model dengan data latih Indo\n",
    "lr_model.fit(X_train_indo, y_train_indo)\n",
    "\n",
    "# Memprediksi data uji Indo\n",
    "y_pred_lr_indo = lr_model.predict(X_test_indo)\n",
    "\n",
    "# Menghitung akurasi Indo\n",
    "print(\"Akurasi Logistic Regression (Indo):\", accuracy_score(y_test_indo, y_pred_lr_indo))\n",
    "print(classification_report(y_test_indo, y_pred_lr_indo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db29be89-6f4a-4c8e-9e5e-fc68e16f3f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Naive Bayes (IMDB): 0.8178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.80      0.81      4961\n",
      "    positive       0.81      0.83      0.82      5039\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "Akurasi Naive Bayes (Indo): 0.7539184952978056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.61      0.67       849\n",
      "     neutral       0.67      0.29      0.41       257\n",
      "    positive       0.76      0.92      0.83      1446\n",
      "\n",
      "    accuracy                           0.75      2552\n",
      "   macro avg       0.73      0.61      0.64      2552\n",
      "weighted avg       0.75      0.75      0.74      2552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Inisialisasi model Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Melatih model dengan data latih IMDB\n",
    "nb_model.fit(X_train_imdb, y_train_imdb)\n",
    "\n",
    "# Memprediksi data uji IMDB\n",
    "y_pred_nb_imdb = nb_model.predict(X_test_imdb)\n",
    "\n",
    "# Menghitung akurasi IMDB\n",
    "print(\"Akurasi Naive Bayes (IMDB):\", accuracy_score(y_test_imdb, y_pred_nb_imdb))\n",
    "print(classification_report(y_test_imdb, y_pred_nb_imdb))\n",
    "\n",
    "# Melatih model dengan data latih Indo\n",
    "nb_model.fit(X_train_indo, y_train_indo)\n",
    "\n",
    "# Memprediksi data uji Indo\n",
    "y_pred_nb_indo = nb_model.predict(X_test_indo)\n",
    "\n",
    "# Menghitung akurasi Indo\n",
    "print(\"Akurasi Naive Bayes (Indo):\", accuracy_score(y_test_indo, y_pred_nb_indo))\n",
    "print(classification_report(y_test_indo, y_pred_nb_indo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5033efaf-9987-4b2d-b586-5aaf18313993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Decision Tree (IMDB): 0.7065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.71      0.71      4961\n",
      "    positive       0.71      0.70      0.71      5039\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n",
      "Akurasi Decision Tree (Indo): 0.7433385579937304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.71      0.67       849\n",
      "     neutral       0.53      0.44      0.48       257\n",
      "    positive       0.85      0.82      0.84      1446\n",
      "\n",
      "    accuracy                           0.74      2552\n",
      "   macro avg       0.67      0.65      0.66      2552\n",
      "weighted avg       0.75      0.74      0.74      2552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Inisialisasi model Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Melatih model dengan data latih IMDB\n",
    "dt_model.fit(X_train_imdb, y_train_imdb)\n",
    "\n",
    "# Memprediksi data uji IMDB\n",
    "y_pred_dt_imdb = dt_model.predict(X_test_imdb)\n",
    "\n",
    "# Menghitung akurasi IMDB\n",
    "print(\"Akurasi Decision Tree (IMDB):\", accuracy_score(y_test_imdb, y_pred_dt_imdb))\n",
    "print(classification_report(y_test_imdb, y_pred_dt_imdb))\n",
    "\n",
    "# Melatih model dengan data latih Indo\n",
    "dt_model.fit(X_train_indo, y_train_indo)\n",
    "\n",
    "# Memprediksi data uji Indo\n",
    "y_pred_dt_indo = dt_model.predict(X_test_indo)\n",
    "\n",
    "# Menghitung akurasi Indo\n",
    "print(\"Akurasi Decision Tree (Indo):\", accuracy_score(y_test_indo, y_pred_dt_indo))\n",
    "print(classification_report(y_test_indo, y_pred_dt_indo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adada453-92fb-4ebc-b54d-5cbcce6d7d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Random Forest (IMDB): 0.8156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81      4961\n",
      "    positive       0.82      0.82      0.82      5039\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "Akurasi Random Forest (Indo): 0.792319749216301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.72      0.71       849\n",
      "     neutral       0.65      0.44      0.53       257\n",
      "    positive       0.86      0.90      0.88      1446\n",
      "\n",
      "    accuracy                           0.79      2552\n",
      "   macro avg       0.74      0.69      0.71      2552\n",
      "weighted avg       0.79      0.79      0.79      2552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Inisialisasi model Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Melatih model dengan data latih IMDB\n",
    "rf_model.fit(X_train_imdb, y_train_imdb)\n",
    "\n",
    "# Memprediksi data uji IMDB\n",
    "y_pred_rf_imdb = rf_model.predict(X_test_imdb)\n",
    "\n",
    "# Menghitung akurasi IMDB\n",
    "print(\"Akurasi Random Forest (IMDB):\", accuracy_score(y_test_imdb, y_pred_rf_imdb))\n",
    "print(classification_report(y_test_imdb, y_pred_rf_imdb))\n",
    "\n",
    "# Melatih model dengan data latih Indo\n",
    "rf_model.fit(X_train_indo, y_train_indo)\n",
    "\n",
    "# Memprediksi data uji Indo\n",
    "y_pred_rf_indo = rf_model.predict(X_test_indo)\n",
    "\n",
    "# Menghitung akurasi Indo\n",
    "print(\"Akurasi Random Forest (Indo):\", accuracy_score(y_test_indo, y_pred_rf_indo))\n",
    "print(classification_report(y_test_indo, y_pred_rf_indo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fdca478-0336-465c-bddd-b98cc29d15c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi SVM (IMDB): 0.8427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84      4961\n",
      "    positive       0.84      0.85      0.85      5039\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "Akurasi SVM (Indo): 0.79858934169279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.78      0.73       849\n",
      "     neutral       0.68      0.39      0.50       257\n",
      "    positive       0.88      0.88      0.88      1446\n",
      "\n",
      "    accuracy                           0.80      2552\n",
      "   macro avg       0.75      0.68      0.70      2552\n",
      "weighted avg       0.80      0.80      0.79      2552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Inisialisasi model SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Melatih model dengan data latih IMDB\n",
    "svm_model.fit(X_train_imdb, y_train_imdb)\n",
    "\n",
    "# Memprediksi data uji IMDB\n",
    "y_pred_svm_imdb = svm_model.predict(X_test_imdb)\n",
    "\n",
    "# Menghitung akurasi IMDB\n",
    "print(\"Akurasi SVM (IMDB):\", accuracy_score(y_test_imdb, y_pred_svm_imdb))\n",
    "print(classification_report(y_test_imdb, y_pred_svm_imdb))\n",
    "\n",
    "# Melatih model dengan data latih Indo\n",
    "svm_model.fit(X_train_indo, y_train_indo)\n",
    "\n",
    "# Memprediksi data uji Indo\n",
    "y_pred_svm_indo = svm_model.predict(X_test_indo)\n",
    "\n",
    "# Menghitung akurasi Indo\n",
    "print(\"Akurasi SVM (Indo):\", accuracy_score(y_test_indo, y_pred_svm_indo))\n",
    "print(classification_report(y_test_indo, y_pred_svm_indo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e775883e-a832-4139-94e5-d6f709f27d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Semua Model:\n",
      "╒════════════════════════════╤════════════╕\n",
      "│ Model                      │   Accuracy │\n",
      "╞════════════════════════════╪════════════╡\n",
      "│ Logistic Regression (IMDB) │   0.843    │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ Logistic Regression (Indo) │   0.794279 │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ Naive Bayes (IMDB)         │   0.8178   │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ Naive Bayes (Indo)         │   0.753918 │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ Decision Tree (IMDB)       │   0.7065   │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ Decision Tree (Indo)       │   0.743339 │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ Random Forest (IMDB)       │   0.8156   │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ Random Forest (Indo)       │   0.79232  │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ SVM (IMDB)                 │   0.8427   │\n",
      "├────────────────────────────┼────────────┤\n",
      "│ SVM (Indo)                 │   0.798589 │\n",
      "╘════════════════════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Membuat dictionary untuk menyimpan hasil akurasi\n",
    "results_dict = {\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression (IMDB)\", \"Logistic Regression (Indo)\",\n",
    "        \"Naive Bayes (IMDB)\", \"Naive Bayes (Indo)\",\n",
    "        \"Decision Tree (IMDB)\", \"Decision Tree (Indo)\",\n",
    "        \"Random Forest (IMDB)\", \"Random Forest (Indo)\",\n",
    "        \"SVM (IMDB)\", \"SVM (Indo)\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test_imdb, y_pred_lr_imdb),\n",
    "        accuracy_score(y_test_indo, y_pred_lr_indo),\n",
    "        accuracy_score(y_test_imdb, y_pred_nb_imdb),\n",
    "        accuracy_score(y_test_indo, y_pred_nb_indo),\n",
    "        accuracy_score(y_test_imdb, y_pred_dt_imdb),\n",
    "        accuracy_score(y_test_indo, y_pred_dt_indo),\n",
    "        accuracy_score(y_test_imdb, y_pred_rf_imdb),\n",
    "        accuracy_score(y_test_indo, y_pred_rf_indo),\n",
    "        accuracy_score(y_test_imdb, y_pred_svm_imdb),\n",
    "        accuracy_score(y_test_indo, y_pred_svm_indo)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Membuat DataFrame dari dictionary\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# Menampilkan hasil evaluasi dalam tabel\n",
    "print(\"Hasil Evaluasi Semua Model:\")\n",
    "print(tabulate(results_df, headers='keys', tablefmt='fancy_grid', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb3adea6-1184-44fc-b6a4-7a35342e4fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Sentimen Dataset IMDB:\n",
      "Naive Bayes: positive\n",
      "Decision Tree: negative\n",
      "Logistic Regression: negative\n",
      "Random Forest: negative\n",
      "SVM: negative\n",
      "\n",
      "Prediksi Sentimen Dataset Bahasa Indonesia:\n",
      "Naive Bayes: positive\n",
      "Decision Tree: positive\n",
      "Logistic Regression: positive\n",
      "Random Forest: positive\n",
      "SVM: positive\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk memprediksi sentimen\n",
    "def predict_sentiment(text, model, vectorizer):\n",
    "    cleaned_text = clean_text(text)\n",
    "    text_vector = vectorizer.transform([cleaned_text]) \n",
    "    prediction = model.predict(text_vector) \n",
    "    return prediction[0]\n",
    "\n",
    "# Teks baru untuk prediksi\n",
    "new_text = \"Saya sangat puas dengan produk ini!\"\n",
    "\n",
    "# Melakukan prediksi dengan berbagai model untuk dataset IMDB\n",
    "print(\"Prediksi Sentimen Dataset IMDB:\")\n",
    "print(\"Naive Bayes:\", predict_sentiment(new_text, nb_model, vectorizer_imdb))\n",
    "print(\"Decision Tree:\", predict_sentiment(new_text, dt_model, vectorizer_imdb))\n",
    "print(\"Logistic Regression:\", predict_sentiment(new_text, lr_model, vectorizer_imdb))\n",
    "print(\"Random Forest:\", predict_sentiment(new_text, rf_model, vectorizer_imdb))\n",
    "print(\"SVM:\", predict_sentiment(new_text, svm_model, vectorizer_imdb))\n",
    "\n",
    "# Melakukan prediksi dengan berbagai model untuk dataset Bahasa Indonesia\n",
    "print(\"\\nPrediksi Sentimen Dataset Bahasa Indonesia:\")\n",
    "print(\"Naive Bayes:\", predict_sentiment(new_text, nb_model, vectorizer_indo))\n",
    "print(\"Decision Tree:\", predict_sentiment(new_text, dt_model, vectorizer_indo))\n",
    "print(\"Logistic Regression:\", predict_sentiment(new_text, lr_model, vectorizer_indo))\n",
    "print(\"Random Forest:\", predict_sentiment(new_text, rf_model, vectorizer_indo))\n",
    "print(\"SVM:\", predict_sentiment(new_text, svm_model, vectorizer_indo))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
